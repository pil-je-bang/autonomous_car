{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tarfile\n",
    "import os\n",
    "import fnmatch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "fname = './drive/MyDrive/line.tar'\n",
    "ap = tarfile.open(fname)\n",
    "ap.extractall('./line')\n",
    "ap.close()\n",
    "data_dir = './line/line'\n",
    "file_list = os.listdir(data_dir)\n",
    "image_paths = []\n",
    "states = []\n",
    "pattern = \"*.png\"\n",
    "for filename in file_list:\n",
    "  if fnmatch.fnmatch(filename, pattern):\n",
    "    image_paths.append(os.path.join(data_dir,filename))\n",
    "    state = str(filename[-5:-4])\n",
    "    states.append(state)\n",
    "images = [cv2.imread(img) for img in image_paths]\n",
    "L_data =[]\n",
    "R_data = []\n",
    "G_data = []\n",
    "for i in range(len(states)):\n",
    "  if states[i] == \"L\":\n",
    "    L_data.append(images[i])\n",
    "  elif states[i] == \"R\":\n",
    "    R_data.append(images[i])\n",
    "  elif states[i] == \"G\":\n",
    "    G_data.append(images[i])\n",
    "images = []\n",
    "states = []\n",
    "for i in range(len(L_data)):\n",
    "  images.append(L_data[i])\n",
    "  states.append(\"L\")\n",
    "for i in range(len(R_data)):\n",
    "  images.append(R_data[i])\n",
    "  states.append(\"R\")\n",
    "for i in range(len(G_data)):\n",
    "  images.append(G_data[i])\n",
    "  states.append(\"G\")\n",
    "df = pd.DataFrame()\n",
    "df['state'] = states\n",
    "df['state'].value_counts()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# OneHotEncoder 생성 및 학습 데이터에 fit\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "labels_encoded = onehot_encoder.fit_transform(np.array(['G', 'L', 'R']).reshape(-1, 1))\n",
    "transform = transforms.Compose([\n",
    "                                #transforms.RandomHorizontalFlip(),\n",
    "                                #transforms.RandomCrop((320, 640), padding=4),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, states, transform=None, train=True, onehot_encoder=None):\n",
    "        self.images = images\n",
    "        self.states = states\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.onehot_encoder = onehot_encoder\n",
    "        # 데이터셋을 train과 test로 나누기\n",
    "        train_size = int(0.8 * len(self.images))\n",
    "        test_size = len(self.images) - train_size\n",
    "        train_data, test_data = train_test_split(list(zip(self.images, self.states)), test_size=test_size, random_state=42)\n",
    "        if self.train:\n",
    "            self.data = train_data\n",
    "        else:\n",
    "            self.data = test_data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    # def __getitem__(self, idx):\n",
    "    #     img_path, state = self.data[idx]\n",
    "    #     img = Image.fromarray(np.asarray(img_path)).convert('RGB')\n",
    "    #     if self.transform:\n",
    "    #         img = self.transform(img)\n",
    "    #     # state를 숫자로 라벨링\n",
    "    #     state = self.label_encoder.transform([state])[0]\n",
    "    #     return img, state\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, state = self.data[idx]\n",
    "        img = Image.fromarray(np.asarray(img_path)).convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        # state를 숫자로 라벨링\n",
    "        # state = self.label_encoder.transform([state])[0]\n",
    "        # state = torch.tensor(state, dtype=torch.long)  # Long 타입으로 변환\n",
    "        # state를 원-핫 인코딩\n",
    "        state_encoded = self.onehot_encoder.transform(np.array(state).reshape(-1, 1))[0]\n",
    "        # cv2.imshow(\"img_path\",img_path)\n",
    "        # cv2.waitKey(0)\n",
    "        # plt.imshow(img_path)\n",
    "        # plt.show()\n",
    "        # print(\"state\", state)\n",
    "        return img, state_encoded\n",
    "# 훈련 데이터에 대해 OneHotEncoder 학습\n",
    "onehot_encoder.fit(np.array(['G', 'L', 'R']).reshape(-1, 1))\n",
    "# 훈련 및 테스트 데이터셋 생성\n",
    "train_dataset = CustomDataset(images=images, states=states, transform=transform, train=True, onehot_encoder=onehot_encoder)\n",
    "test_dataset = CustomDataset(images=images, states=states, transform=transform, train=False, onehot_encoder=onehot_encoder)\n",
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# 간단한 CNN 모델 정의\n",
    "class RoadClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(RoadClassifier, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        in_features = self.cnn.fc.in_features\n",
    "        self.cnn.fc = nn.Linear(in_features, num_classes)\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "# 모델, 손실 함수, 최적화기 정의\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RoadClassifier(num_classes=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# 학습하기\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        print('outputs', outputs[0], 'labels', labels[0])\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / i}\")\n",
    "print(\"학습 완료\")\n",
    "# 테스트하기\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predicted = torch.argmax(outputs.data, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "print(f\"Accuracy: {100 * correct / total}%\")\n",
    "torch.save(model.state_dict(), 'road_classifier_model.pth')\n",
    "# loaded_model = RoadClassifier(num_classes=3).to(device)\n",
    "# loaded_model.load_state_dict(torch.load('road_classifier_model.pth'))\n",
    "# loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./line/_00014_R.png')\n",
    "a = Image.fromarray(np.asarray(img)).convert('RGB')\n",
    "# 이미지 변환 및 차원 추가\n",
    "transformed_image = transform(a).unsqueeze(0).to(device)\n",
    "result = model(transformed_image)\n",
    "print(result)\n",
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
